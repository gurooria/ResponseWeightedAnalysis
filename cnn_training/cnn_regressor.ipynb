{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VelocityCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VelocityCNN, self).__init__()    \n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(15, 32, kernel_size=7, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=5, padding=1)\n",
    "        self.norm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Define regressor\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * 2 * 2, 128),  # Adjust the size based on the output from the last pooling layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 6)  # Output Layer for x, y coordinates and velocity\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with activations, pooling and normalization\n",
    "        x1 = self.conv1(x)\n",
    "        x = self.relu(x1)\n",
    "        x = self.norm1(self.pool(x))\n",
    "        x2 = self.conv2(x)\n",
    "        x = self.relu(x2)\n",
    "        x = self.norm2(self.pool(x))\n",
    "        x3 = self.conv3(x)\n",
    "        x = self.relu(x3)\n",
    "        x = self.norm3(self.pool(x))\n",
    "        \n",
    "        # Apply regressor\n",
    "        x = self.regressor(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class LocalizationCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LocalizationCNN, self).__init__()\n",
    "        \n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(15, 32, kernel_size=7, padding=1)\n",
    "        self.norm1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, padding=1)\n",
    "        self.norm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        # self.norm3 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Define regressor\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(64 * 6 * 6, 128),  # Adjust the size based on the output from the last pooling layer\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(128, 6)  # Output Layer for x, y coordinates and velocity\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply convolutional layers with activations, pooling and normalization\n",
    "        x1 = self.conv1(x)\n",
    "        x = self.relu(x1)\n",
    "        x = self.norm1(self.pool(x))\n",
    "        x2 = self.conv2(x)\n",
    "        x = self.relu(x2)\n",
    "        x = self.norm2(self.pool(x))\n",
    "        # x3 = self.conv3(x)\n",
    "        # x = self.relu(x3)\n",
    "        # x = self.norm3(self.pool(x))\n",
    "        \n",
    "        # Apply regressor\n",
    "        x = self.regressor(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# Load and prepare the dataset\n",
    "def load_data(X, Y, training_size=0.8):\n",
    "    dataset = TensorDataset(X, Y)\n",
    "\n",
    "    # Splitting dataset into training and validation\n",
    "    train_size = int(training_size * len(dataset))\n",
    "    val_size = len(dataset) - train_size\n",
    "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "def train_model(model, device, train_loader, val_loader, optimizer, loss_function, epochs):\n",
    "    model.train()\n",
    "    training_losses = []\n",
    "    validate_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for data, target in train_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "        training_avg_loss = total_loss / len(train_loader.dataset)\n",
    "        training_losses.append(training_avg_loss) # average loss for each epoch\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "        validate_avg_loss = total_loss / len(val_loader.dataset)\n",
    "        validate_losses.append(validate_avg_loss)\n",
    "        print(f'Epoch {epoch+1}, Training Loss: {training_avg_loss:.7f}, Validation Loss: {validate_avg_loss:.7f}')\n",
    "    return training_losses, validate_losses\n",
    "\n",
    "def validate_model(model, device, val_loader, loss_function):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in val_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            total_loss += loss.item() * data.size(0)\n",
    "    avg_loss = total_loss / len(val_loader.dataset)\n",
    "    print(f'Validation Loss: {avg_loss:.4f}')\n",
    "    return avg_loss\n",
    "\n",
    "def plot_learning_curves(training_losses, validation_losses, start, title):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(training_losses[start:], label='Training Loss')\n",
    "    plt.plot(validation_losses[start:], label='Validation Loss')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 15, 32, 32]) torch.Size([2000, 6])\n"
     ]
    }
   ],
   "source": [
    "# load training data\n",
    "X = torch.load('training_images32.pt')\n",
    "Y = torch.load('position_labels32.pt')\n",
    "# Y = torch.load('velocity_labels32.pt')\n",
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "# Load data\n",
    "train_dataset, val_dataset = load_data(X, Y)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.0978176, Validation Loss: 0.4443363\n",
      "Epoch 2, Training Loss: 0.0419383, Validation Loss: 0.2058407\n",
      "Epoch 3, Training Loss: 0.0363461, Validation Loss: 0.1769520\n",
      "Epoch 4, Training Loss: 0.0307003, Validation Loss: 0.1534711\n",
      "Epoch 5, Training Loss: 0.0290292, Validation Loss: 0.1434190\n",
      "Epoch 6, Training Loss: 0.0296239, Validation Loss: 0.1485286\n",
      "Epoch 7, Training Loss: 0.0305433, Validation Loss: 0.1501237\n",
      "Epoch 8, Training Loss: 0.0277082, Validation Loss: 0.1387919\n",
      "Epoch 9, Training Loss: 0.0246839, Validation Loss: 0.1206740\n",
      "Epoch 10, Training Loss: 0.0225710, Validation Loss: 0.1113297\n",
      "Epoch 11, Training Loss: 0.0222589, Validation Loss: 0.1113733\n",
      "Epoch 12, Training Loss: 0.0227523, Validation Loss: 0.1126049\n",
      "Epoch 13, Training Loss: 0.0196030, Validation Loss: 0.1037513\n",
      "Epoch 14, Training Loss: 0.0229088, Validation Loss: 0.1114245\n",
      "Epoch 15, Training Loss: 0.0194543, Validation Loss: 0.0952328\n",
      "Epoch 16, Training Loss: 0.0204089, Validation Loss: 0.1018574\n",
      "Epoch 17, Training Loss: 0.0227104, Validation Loss: 0.1230990\n",
      "Epoch 18, Training Loss: 0.0233048, Validation Loss: 0.1135772\n",
      "Epoch 19, Training Loss: 0.0187587, Validation Loss: 0.0913807\n",
      "Epoch 20, Training Loss: 0.0173734, Validation Loss: 0.0863203\n",
      "Epoch 21, Training Loss: 0.0200412, Validation Loss: 0.1002051\n",
      "Epoch 22, Training Loss: 0.0213518, Validation Loss: 0.1112834\n",
      "Epoch 23, Training Loss: 0.0184641, Validation Loss: 0.0898170\n",
      "Epoch 24, Training Loss: 0.0162782, Validation Loss: 0.0811057\n",
      "Epoch 25, Training Loss: 0.0169729, Validation Loss: 0.0835359\n",
      "Epoch 26, Training Loss: 0.0187883, Validation Loss: 0.0967617\n",
      "Epoch 27, Training Loss: 0.0182079, Validation Loss: 0.0907184\n",
      "Epoch 28, Training Loss: 0.0175223, Validation Loss: 0.0899731\n",
      "Epoch 29, Training Loss: 0.0168504, Validation Loss: 0.0831172\n",
      "Epoch 30, Training Loss: 0.0177187, Validation Loss: 0.0868634\n",
      "Epoch 31, Training Loss: 0.0159529, Validation Loss: 0.0785630\n",
      "Epoch 32, Training Loss: 0.0183321, Validation Loss: 0.0875110\n",
      "Epoch 33, Training Loss: 0.0169897, Validation Loss: 0.0821313\n",
      "Epoch 34, Training Loss: 0.0146109, Validation Loss: 0.0736608\n",
      "Epoch 35, Training Loss: 0.0158129, Validation Loss: 0.0816272\n",
      "Epoch 36, Training Loss: 0.0166129, Validation Loss: 0.0812072\n",
      "Epoch 37, Training Loss: 0.0152579, Validation Loss: 0.0754020\n",
      "Epoch 38, Training Loss: 0.0155298, Validation Loss: 0.0750936\n",
      "Epoch 39, Training Loss: 0.0150112, Validation Loss: 0.0740857\n",
      "Epoch 40, Training Loss: 0.0169493, Validation Loss: 0.0806385\n",
      "Epoch 41, Training Loss: 0.0145544, Validation Loss: 0.0720023\n",
      "Epoch 42, Training Loss: 0.0145679, Validation Loss: 0.0717182\n",
      "Epoch 43, Training Loss: 0.0145340, Validation Loss: 0.0755886\n",
      "Epoch 44, Training Loss: 0.0154054, Validation Loss: 0.0761098\n",
      "Epoch 45, Training Loss: 0.0161736, Validation Loss: 0.0765666\n",
      "Epoch 46, Training Loss: 0.0135506, Validation Loss: 0.0683896\n",
      "Epoch 47, Training Loss: 0.0144145, Validation Loss: 0.0709588\n",
      "Epoch 48, Training Loss: 0.0141194, Validation Loss: 0.0745211\n",
      "Epoch 49, Training Loss: 0.0140130, Validation Loss: 0.0694406\n",
      "Epoch 50, Training Loss: 0.0130565, Validation Loss: 0.0684288\n",
      "Epoch 51, Training Loss: 0.0140183, Validation Loss: 0.0684172\n",
      "Epoch 52, Training Loss: 0.0127784, Validation Loss: 0.0646383\n",
      "Epoch 53, Training Loss: 0.0141997, Validation Loss: 0.0703591\n",
      "Epoch 54, Training Loss: 0.0130121, Validation Loss: 0.0642419\n",
      "Epoch 55, Training Loss: 0.0136238, Validation Loss: 0.0677553\n",
      "Epoch 56, Training Loss: 0.0142227, Validation Loss: 0.0681895\n",
      "Epoch 57, Training Loss: 0.0148320, Validation Loss: 0.0754260\n",
      "Epoch 58, Training Loss: 0.0138489, Validation Loss: 0.0698966\n",
      "Epoch 59, Training Loss: 0.0130220, Validation Loss: 0.0651581\n",
      "Epoch 60, Training Loss: 0.0121141, Validation Loss: 0.0616548\n",
      "Epoch 61, Training Loss: 0.0123589, Validation Loss: 0.0635135\n",
      "Epoch 62, Training Loss: 0.0125435, Validation Loss: 0.0623174\n",
      "Epoch 63, Training Loss: 0.0126323, Validation Loss: 0.0622709\n",
      "Epoch 64, Training Loss: 0.0120254, Validation Loss: 0.0602494\n",
      "Epoch 65, Training Loss: 0.0115243, Validation Loss: 0.0595673\n",
      "Epoch 66, Training Loss: 0.0123909, Validation Loss: 0.0595675\n",
      "Epoch 67, Training Loss: 0.0119365, Validation Loss: 0.0604963\n",
      "Epoch 68, Training Loss: 0.0113270, Validation Loss: 0.0572955\n",
      "Epoch 69, Training Loss: 0.0115110, Validation Loss: 0.0583429\n",
      "Epoch 70, Training Loss: 0.0121299, Validation Loss: 0.0609273\n",
      "Epoch 71, Training Loss: 0.0114449, Validation Loss: 0.0572938\n",
      "Epoch 72, Training Loss: 0.0116926, Validation Loss: 0.0579774\n",
      "Epoch 73, Training Loss: 0.0111501, Validation Loss: 0.0561548\n",
      "Epoch 74, Training Loss: 0.0118288, Validation Loss: 0.0593822\n",
      "Epoch 75, Training Loss: 0.0108640, Validation Loss: 0.0551344\n",
      "Epoch 76, Training Loss: 0.0118292, Validation Loss: 0.0577534\n",
      "Epoch 77, Training Loss: 0.0107108, Validation Loss: 0.0543145\n",
      "Epoch 78, Training Loss: 0.0110495, Validation Loss: 0.0558483\n",
      "Epoch 79, Training Loss: 0.0119205, Validation Loss: 0.0582549\n",
      "Epoch 80, Training Loss: 0.0110389, Validation Loss: 0.0552860\n",
      "Epoch 81, Training Loss: 0.0110115, Validation Loss: 0.0546767\n",
      "Epoch 82, Training Loss: 0.0109296, Validation Loss: 0.0551260\n",
      "Epoch 83, Training Loss: 0.0114294, Validation Loss: 0.0562786\n",
      "Epoch 84, Training Loss: 0.0114573, Validation Loss: 0.0576169\n",
      "Epoch 85, Training Loss: 0.0102586, Validation Loss: 0.0500466\n",
      "Epoch 86, Training Loss: 0.0102891, Validation Loss: 0.0510319\n",
      "Epoch 87, Training Loss: 0.0113441, Validation Loss: 0.0566132\n",
      "Epoch 88, Training Loss: 0.0104700, Validation Loss: 0.0519929\n",
      "Epoch 89, Training Loss: 0.0103780, Validation Loss: 0.0519729\n",
      "Epoch 90, Training Loss: 0.0097790, Validation Loss: 0.0483835\n",
      "Epoch 91, Training Loss: 0.0104008, Validation Loss: 0.0508148\n",
      "Epoch 92, Training Loss: 0.0100948, Validation Loss: 0.0509112\n",
      "Epoch 93, Training Loss: 0.0099293, Validation Loss: 0.0509286\n",
      "Epoch 94, Training Loss: 0.0104225, Validation Loss: 0.0509208\n",
      "Epoch 95, Training Loss: 0.0101152, Validation Loss: 0.0521295\n",
      "Epoch 96, Training Loss: 0.0099443, Validation Loss: 0.0482712\n",
      "Epoch 97, Training Loss: 0.0092134, Validation Loss: 0.0463956\n",
      "Epoch 98, Training Loss: 0.0096422, Validation Loss: 0.0478854\n",
      "Epoch 99, Training Loss: 0.0082647, Validation Loss: 0.0422314\n",
      "Epoch 100, Training Loss: 0.0094753, Validation Loss: 0.0462297\n",
      "Epoch 101, Training Loss: 0.0094460, Validation Loss: 0.0478290\n",
      "Epoch 102, Training Loss: 0.0092303, Validation Loss: 0.0461230\n",
      "Epoch 103, Training Loss: 0.0093633, Validation Loss: 0.0473099\n",
      "Epoch 104, Training Loss: 0.0089808, Validation Loss: 0.0459741\n",
      "Epoch 105, Training Loss: 0.0093946, Validation Loss: 0.0463936\n",
      "Epoch 106, Training Loss: 0.0084098, Validation Loss: 0.0434688\n",
      "Epoch 107, Training Loss: 0.0092230, Validation Loss: 0.0455240\n",
      "Epoch 108, Training Loss: 0.0090206, Validation Loss: 0.0453264\n",
      "Epoch 109, Training Loss: 0.0087910, Validation Loss: 0.0438021\n",
      "Epoch 110, Training Loss: 0.0083266, Validation Loss: 0.0413866\n",
      "Epoch 111, Training Loss: 0.0087787, Validation Loss: 0.0435119\n",
      "Epoch 112, Training Loss: 0.0080191, Validation Loss: 0.0399481\n",
      "Epoch 113, Training Loss: 0.0082221, Validation Loss: 0.0412950\n",
      "Epoch 114, Training Loss: 0.0083224, Validation Loss: 0.0423547\n",
      "Epoch 115, Training Loss: 0.0084993, Validation Loss: 0.0417457\n",
      "Epoch 116, Training Loss: 0.0076818, Validation Loss: 0.0388100\n",
      "Epoch 117, Training Loss: 0.0082630, Validation Loss: 0.0400300\n",
      "Epoch 118, Training Loss: 0.0080849, Validation Loss: 0.0396790\n",
      "Epoch 119, Training Loss: 0.0078515, Validation Loss: 0.0391397\n",
      "Epoch 120, Training Loss: 0.0077641, Validation Loss: 0.0383215\n",
      "Epoch 121, Training Loss: 0.0072648, Validation Loss: 0.0369316\n",
      "Epoch 122, Training Loss: 0.0080202, Validation Loss: 0.0402492\n",
      "Epoch 123, Training Loss: 0.0071647, Validation Loss: 0.0362307\n",
      "Epoch 124, Training Loss: 0.0074475, Validation Loss: 0.0363581\n",
      "Epoch 125, Training Loss: 0.0075258, Validation Loss: 0.0378368\n",
      "Epoch 126, Training Loss: 0.0075094, Validation Loss: 0.0379192\n",
      "Epoch 127, Training Loss: 0.0070889, Validation Loss: 0.0355410\n",
      "Epoch 128, Training Loss: 0.0071838, Validation Loss: 0.0357755\n",
      "Epoch 129, Training Loss: 0.0071045, Validation Loss: 0.0354318\n",
      "Epoch 130, Training Loss: 0.0068418, Validation Loss: 0.0342969\n",
      "Epoch 131, Training Loss: 0.0070431, Validation Loss: 0.0352807\n",
      "Epoch 132, Training Loss: 0.0069118, Validation Loss: 0.0338168\n",
      "Epoch 133, Training Loss: 0.0069353, Validation Loss: 0.0342123\n",
      "Epoch 134, Training Loss: 0.0069125, Validation Loss: 0.0347096\n",
      "Epoch 135, Training Loss: 0.0066209, Validation Loss: 0.0328295\n",
      "Epoch 136, Training Loss: 0.0065853, Validation Loss: 0.0334561\n",
      "Epoch 137, Training Loss: 0.0064325, Validation Loss: 0.0323086\n",
      "Epoch 138, Training Loss: 0.0062933, Validation Loss: 0.0312889\n",
      "Epoch 139, Training Loss: 0.0069620, Validation Loss: 0.0344743\n",
      "Epoch 140, Training Loss: 0.0061202, Validation Loss: 0.0306556\n",
      "Epoch 141, Training Loss: 0.0064958, Validation Loss: 0.0326346\n",
      "Epoch 142, Training Loss: 0.0063095, Validation Loss: 0.0319634\n",
      "Epoch 143, Training Loss: 0.0062762, Validation Loss: 0.0324197\n",
      "Epoch 144, Training Loss: 0.0063398, Validation Loss: 0.0317545\n",
      "Epoch 145, Training Loss: 0.0059168, Validation Loss: 0.0296644\n",
      "Epoch 146, Training Loss: 0.0061724, Validation Loss: 0.0305525\n",
      "Epoch 147, Training Loss: 0.0058062, Validation Loss: 0.0289446\n",
      "Epoch 148, Training Loss: 0.0059142, Validation Loss: 0.0291705\n",
      "Epoch 149, Training Loss: 0.0059352, Validation Loss: 0.0306051\n",
      "Epoch 150, Training Loss: 0.0056966, Validation Loss: 0.0288616\n",
      "Epoch 151, Training Loss: 0.0059927, Validation Loss: 0.0304630\n",
      "Epoch 152, Training Loss: 0.0058184, Validation Loss: 0.0285969\n",
      "Epoch 153, Training Loss: 0.0057365, Validation Loss: 0.0288945\n",
      "Epoch 154, Training Loss: 0.0055401, Validation Loss: 0.0272936\n",
      "Epoch 155, Training Loss: 0.0054521, Validation Loss: 0.0273145\n",
      "Epoch 156, Training Loss: 0.0055632, Validation Loss: 0.0279690\n",
      "Epoch 157, Training Loss: 0.0053290, Validation Loss: 0.0280055\n",
      "Epoch 158, Training Loss: 0.0053766, Validation Loss: 0.0265728\n",
      "Epoch 159, Training Loss: 0.0051858, Validation Loss: 0.0258791\n",
      "Epoch 160, Training Loss: 0.0053150, Validation Loss: 0.0260520\n",
      "Epoch 161, Training Loss: 0.0051139, Validation Loss: 0.0256373\n",
      "Epoch 162, Training Loss: 0.0053910, Validation Loss: 0.0265749\n",
      "Epoch 163, Training Loss: 0.0050889, Validation Loss: 0.0250653\n",
      "Epoch 164, Training Loss: 0.0050115, Validation Loss: 0.0249465\n",
      "Epoch 165, Training Loss: 0.0054104, Validation Loss: 0.0261386\n",
      "Epoch 166, Training Loss: 0.0056539, Validation Loss: 0.0277124\n",
      "Epoch 167, Training Loss: 0.0049543, Validation Loss: 0.0242356\n",
      "Epoch 168, Training Loss: 0.0048854, Validation Loss: 0.0245699\n",
      "Epoch 169, Training Loss: 0.0049447, Validation Loss: 0.0248047\n",
      "Epoch 170, Training Loss: 0.0048642, Validation Loss: 0.0237942\n",
      "Epoch 171, Training Loss: 0.0044807, Validation Loss: 0.0226265\n",
      "Epoch 172, Training Loss: 0.0046720, Validation Loss: 0.0229629\n",
      "Epoch 173, Training Loss: 0.0046355, Validation Loss: 0.0226102\n",
      "Epoch 174, Training Loss: 0.0046986, Validation Loss: 0.0232468\n",
      "Epoch 175, Training Loss: 0.0045710, Validation Loss: 0.0226616\n",
      "Epoch 176, Training Loss: 0.0045553, Validation Loss: 0.0222874\n",
      "Epoch 177, Training Loss: 0.0045189, Validation Loss: 0.0224856\n",
      "Epoch 178, Training Loss: 0.0046352, Validation Loss: 0.0244510\n",
      "Epoch 179, Training Loss: 0.0047233, Validation Loss: 0.0231419\n",
      "Epoch 180, Training Loss: 0.0042232, Validation Loss: 0.0211477\n",
      "Epoch 181, Training Loss: 0.0041582, Validation Loss: 0.0200748\n",
      "Epoch 182, Training Loss: 0.0042388, Validation Loss: 0.0209478\n",
      "Epoch 183, Training Loss: 0.0039300, Validation Loss: 0.0199773\n",
      "Epoch 184, Training Loss: 0.0038884, Validation Loss: 0.0194259\n",
      "Epoch 185, Training Loss: 0.0038257, Validation Loss: 0.0188449\n",
      "Epoch 186, Training Loss: 0.0036930, Validation Loss: 0.0186395\n",
      "Epoch 187, Training Loss: 0.0040003, Validation Loss: 0.0198515\n",
      "Epoch 188, Training Loss: 0.0038775, Validation Loss: 0.0193047\n",
      "Epoch 189, Training Loss: 0.0036380, Validation Loss: 0.0183553\n",
      "Epoch 190, Training Loss: 0.0036871, Validation Loss: 0.0188028\n",
      "Epoch 191, Training Loss: 0.0035760, Validation Loss: 0.0178787\n",
      "Epoch 192, Training Loss: 0.0035096, Validation Loss: 0.0182467\n",
      "Epoch 193, Training Loss: 0.0036416, Validation Loss: 0.0183500\n",
      "Epoch 194, Training Loss: 0.0038534, Validation Loss: 0.0190626\n",
      "Epoch 195, Training Loss: 0.0035075, Validation Loss: 0.0175557\n",
      "Epoch 196, Training Loss: 0.0032864, Validation Loss: 0.0166914\n",
      "Epoch 197, Training Loss: 0.0035862, Validation Loss: 0.0180846\n",
      "Epoch 198, Training Loss: 0.0035578, Validation Loss: 0.0175859\n",
      "Epoch 199, Training Loss: 0.0032810, Validation Loss: 0.0164709\n",
      "Epoch 200, Training Loss: 0.0032266, Validation Loss: 0.0162107\n",
      "Epoch 201, Training Loss: 0.0032818, Validation Loss: 0.0164235\n",
      "Epoch 202, Training Loss: 0.0031825, Validation Loss: 0.0161412\n",
      "Epoch 203, Training Loss: 0.0032581, Validation Loss: 0.0161724\n",
      "Epoch 204, Training Loss: 0.0030084, Validation Loss: 0.0152145\n",
      "Epoch 205, Training Loss: 0.0032137, Validation Loss: 0.0163601\n",
      "Epoch 206, Training Loss: 0.0030588, Validation Loss: 0.0152275\n",
      "Epoch 207, Training Loss: 0.0029587, Validation Loss: 0.0151203\n",
      "Epoch 208, Training Loss: 0.0029140, Validation Loss: 0.0143097\n",
      "Epoch 209, Training Loss: 0.0031491, Validation Loss: 0.0154208\n",
      "Epoch 210, Training Loss: 0.0028847, Validation Loss: 0.0146289\n",
      "Epoch 211, Training Loss: 0.0028429, Validation Loss: 0.0146012\n",
      "Epoch 212, Training Loss: 0.0028558, Validation Loss: 0.0139966\n",
      "Epoch 213, Training Loss: 0.0026645, Validation Loss: 0.0135352\n",
      "Epoch 214, Training Loss: 0.0026304, Validation Loss: 0.0134037\n",
      "Epoch 215, Training Loss: 0.0027352, Validation Loss: 0.0136883\n",
      "Epoch 216, Training Loss: 0.0027697, Validation Loss: 0.0138670\n",
      "Epoch 217, Training Loss: 0.0026508, Validation Loss: 0.0135578\n",
      "Epoch 218, Training Loss: 0.0025738, Validation Loss: 0.0126540\n",
      "Epoch 219, Training Loss: 0.0024141, Validation Loss: 0.0121934\n",
      "Epoch 220, Training Loss: 0.0025421, Validation Loss: 0.0127054\n",
      "Epoch 221, Training Loss: 0.0024448, Validation Loss: 0.0121064\n",
      "Epoch 222, Training Loss: 0.0024554, Validation Loss: 0.0124275\n",
      "Epoch 223, Training Loss: 0.0023577, Validation Loss: 0.0116699\n",
      "Epoch 224, Training Loss: 0.0024077, Validation Loss: 0.0121664\n",
      "Epoch 225, Training Loss: 0.0024583, Validation Loss: 0.0120440\n",
      "Epoch 226, Training Loss: 0.0024960, Validation Loss: 0.0124923\n",
      "Epoch 227, Training Loss: 0.0023396, Validation Loss: 0.0116624\n",
      "Epoch 228, Training Loss: 0.0024329, Validation Loss: 0.0120226\n",
      "Epoch 229, Training Loss: 0.0022675, Validation Loss: 0.0115053\n",
      "Epoch 230, Training Loss: 0.0022390, Validation Loss: 0.0111568\n",
      "Epoch 231, Training Loss: 0.0020977, Validation Loss: 0.0103033\n",
      "Epoch 232, Training Loss: 0.0021547, Validation Loss: 0.0108261\n",
      "Epoch 233, Training Loss: 0.0021075, Validation Loss: 0.0107045\n",
      "Epoch 234, Training Loss: 0.0021091, Validation Loss: 0.0106871\n",
      "Epoch 235, Training Loss: 0.0020325, Validation Loss: 0.0103522\n",
      "Epoch 236, Training Loss: 0.0020089, Validation Loss: 0.0101870\n",
      "Epoch 237, Training Loss: 0.0020048, Validation Loss: 0.0101282\n",
      "Epoch 238, Training Loss: 0.0019084, Validation Loss: 0.0094392\n",
      "Epoch 239, Training Loss: 0.0019444, Validation Loss: 0.0213125\n",
      "Epoch 240, Training Loss: 0.0031711, Validation Loss: 0.0147688\n",
      "Epoch 241, Training Loss: 0.0020847, Validation Loss: 0.0103409\n",
      "Epoch 242, Training Loss: 0.0019846, Validation Loss: 0.0097211\n",
      "Epoch 243, Training Loss: 0.0017811, Validation Loss: 0.0088878\n",
      "Epoch 244, Training Loss: 0.0017575, Validation Loss: 0.0087303\n",
      "Epoch 245, Training Loss: 0.0018268, Validation Loss: 0.0092560\n",
      "Epoch 246, Training Loss: 0.0017073, Validation Loss: 0.0086153\n",
      "Epoch 247, Training Loss: 0.0017394, Validation Loss: 0.0090639\n",
      "Epoch 248, Training Loss: 0.0018247, Validation Loss: 0.0089824\n",
      "Epoch 249, Training Loss: 0.0016593, Validation Loss: 0.0083936\n",
      "Epoch 250, Training Loss: 0.0015567, Validation Loss: 0.0080105\n",
      "Epoch 251, Training Loss: 0.0015737, Validation Loss: 0.0079580\n",
      "Epoch 252, Training Loss: 0.0016590, Validation Loss: 0.0082078\n",
      "Epoch 253, Training Loss: 0.0015610, Validation Loss: 0.0080290\n",
      "Epoch 254, Training Loss: 0.0016488, Validation Loss: 0.0080862\n",
      "Epoch 255, Training Loss: 0.0014833, Validation Loss: 0.0075387\n",
      "Epoch 256, Training Loss: 0.0014554, Validation Loss: 0.0072252\n",
      "Epoch 257, Training Loss: 0.0014869, Validation Loss: 0.0074194\n",
      "Epoch 258, Training Loss: 0.0014932, Validation Loss: 0.0073429\n",
      "Epoch 259, Training Loss: 0.0013730, Validation Loss: 0.0069307\n",
      "Epoch 260, Training Loss: 0.0014012, Validation Loss: 0.0070433\n",
      "Epoch 261, Training Loss: 0.0013888, Validation Loss: 0.0069533\n",
      "Epoch 262, Training Loss: 0.0014236, Validation Loss: 0.0070822\n",
      "Epoch 263, Training Loss: 0.0012626, Validation Loss: 0.0064496\n",
      "Epoch 264, Training Loss: 0.0013685, Validation Loss: 0.0068170\n",
      "Epoch 265, Training Loss: 0.0013575, Validation Loss: 0.0067739\n",
      "Epoch 266, Training Loss: 0.0012802, Validation Loss: 0.0063064\n",
      "Epoch 267, Training Loss: 0.0012318, Validation Loss: 0.0062875\n",
      "Epoch 268, Training Loss: 0.0012051, Validation Loss: 0.0061507\n",
      "Epoch 269, Training Loss: 0.0012075, Validation Loss: 0.0061186\n",
      "Epoch 270, Training Loss: 0.0011877, Validation Loss: 0.0059277\n",
      "Epoch 271, Training Loss: 0.0011993, Validation Loss: 0.0060543\n",
      "Epoch 272, Training Loss: 0.0012251, Validation Loss: 0.0061005\n",
      "Epoch 273, Training Loss: 0.0012252, Validation Loss: 0.0060784\n",
      "Epoch 274, Training Loss: 0.0011973, Validation Loss: 0.0058923\n",
      "Epoch 275, Training Loss: 0.0011611, Validation Loss: 0.0057523\n",
      "Epoch 276, Training Loss: 0.0011789, Validation Loss: 0.0057446\n",
      "Epoch 277, Training Loss: 0.0011254, Validation Loss: 0.0056790\n",
      "Epoch 278, Training Loss: 0.0011299, Validation Loss: 0.0055844\n",
      "Epoch 279, Training Loss: 0.0010267, Validation Loss: 0.0052513\n",
      "Epoch 280, Training Loss: 0.0010685, Validation Loss: 0.0054134\n",
      "Epoch 281, Training Loss: 0.0010542, Validation Loss: 0.0052219\n",
      "Epoch 282, Training Loss: 0.0010671, Validation Loss: 0.0054774\n",
      "Epoch 283, Training Loss: 0.0010029, Validation Loss: 0.0050740\n",
      "Epoch 284, Training Loss: 0.0010075, Validation Loss: 0.0049991\n",
      "Epoch 285, Training Loss: 0.0009522, Validation Loss: 0.0048106\n",
      "Epoch 286, Training Loss: 0.0009653, Validation Loss: 0.0048110\n",
      "Epoch 287, Training Loss: 0.0010131, Validation Loss: 0.0050123\n",
      "Epoch 288, Training Loss: 0.0009918, Validation Loss: 0.0050530\n",
      "Epoch 289, Training Loss: 0.0009530, Validation Loss: 0.0046340\n",
      "Epoch 290, Training Loss: 0.0009426, Validation Loss: 0.0047789\n",
      "Epoch 291, Training Loss: 0.0009102, Validation Loss: 0.0045385\n",
      "Epoch 292, Training Loss: 0.0009331, Validation Loss: 0.0046947\n",
      "Epoch 293, Training Loss: 0.0009300, Validation Loss: 0.0047135\n",
      "Epoch 294, Training Loss: 0.0009031, Validation Loss: 0.0046701\n",
      "Epoch 295, Training Loss: 0.0008727, Validation Loss: 0.0044068\n",
      "Epoch 296, Training Loss: 0.0008177, Validation Loss: 0.0042786\n",
      "Epoch 297, Training Loss: 0.0008686, Validation Loss: 0.0043353\n",
      "Epoch 298, Training Loss: 0.0008773, Validation Loss: 0.0044471\n",
      "Epoch 299, Training Loss: 0.0008627, Validation Loss: 0.0043968\n",
      "Epoch 300, Training Loss: 0.0008658, Validation Loss: 0.0042701\n",
      "Epoch 301, Training Loss: 0.0008218, Validation Loss: 0.0041718\n",
      "Epoch 302, Training Loss: 0.0008302, Validation Loss: 0.0042329\n",
      "Epoch 303, Training Loss: 0.0008565, Validation Loss: 0.0043051\n",
      "Epoch 304, Training Loss: 0.0008528, Validation Loss: 0.0042878\n",
      "Epoch 305, Training Loss: 0.0007987, Validation Loss: 0.0040406\n",
      "Epoch 306, Training Loss: 0.0008834, Validation Loss: 0.0044450\n",
      "Epoch 307, Training Loss: 0.0008418, Validation Loss: 0.0042538\n",
      "Epoch 308, Training Loss: 0.0008146, Validation Loss: 0.0040694\n",
      "Epoch 309, Training Loss: 0.0008205, Validation Loss: 0.0041197\n",
      "Epoch 310, Training Loss: 0.0007860, Validation Loss: 0.0039166\n",
      "Epoch 311, Training Loss: 0.0007711, Validation Loss: 0.0038661\n",
      "Epoch 312, Training Loss: 0.0007638, Validation Loss: 0.0038481\n",
      "Epoch 313, Training Loss: 0.0008072, Validation Loss: 0.0039881\n",
      "Epoch 314, Training Loss: 0.0007912, Validation Loss: 0.0039879\n",
      "Epoch 315, Training Loss: 0.0008131, Validation Loss: 0.0039694\n",
      "Epoch 316, Training Loss: 0.0008077, Validation Loss: 0.0040155\n",
      "Epoch 317, Training Loss: 0.0007924, Validation Loss: 0.0039833\n",
      "Epoch 318, Training Loss: 0.0007988, Validation Loss: 0.0040258\n",
      "Epoch 319, Training Loss: 0.0007384, Validation Loss: 0.0037849\n",
      "Epoch 320, Training Loss: 0.0007651, Validation Loss: 0.0037979\n",
      "Epoch 321, Training Loss: 0.0007761, Validation Loss: 0.0038364\n",
      "Epoch 322, Training Loss: 0.0007554, Validation Loss: 0.0037805\n",
      "Epoch 323, Training Loss: 0.0007297, Validation Loss: 0.0036813\n",
      "Epoch 324, Training Loss: 0.0007553, Validation Loss: 0.0038030\n",
      "Epoch 325, Training Loss: 0.0007671, Validation Loss: 0.0039210\n",
      "Epoch 326, Training Loss: 0.0007561, Validation Loss: 0.0037067\n",
      "Epoch 327, Training Loss: 0.0007595, Validation Loss: 0.0037598\n",
      "Epoch 328, Training Loss: 0.0007376, Validation Loss: 0.0037206\n",
      "Epoch 329, Training Loss: 0.0007548, Validation Loss: 0.0037567\n",
      "Epoch 330, Training Loss: 0.0007278, Validation Loss: 0.0036859\n",
      "Epoch 331, Training Loss: 0.0007649, Validation Loss: 0.0038077\n",
      "Epoch 332, Training Loss: 0.0007725, Validation Loss: 0.0038443\n",
      "Epoch 333, Training Loss: 0.0007363, Validation Loss: 0.0036465\n",
      "Epoch 334, Training Loss: 0.0007320, Validation Loss: 0.0037007\n",
      "Epoch 335, Training Loss: 0.0007569, Validation Loss: 0.0037562\n",
      "Epoch 336, Training Loss: 0.0007208, Validation Loss: 0.0036398\n",
      "Epoch 337, Training Loss: 0.0007190, Validation Loss: 0.0036163\n",
      "Epoch 338, Training Loss: 0.0007265, Validation Loss: 0.0037054\n",
      "Epoch 339, Training Loss: 0.0007661, Validation Loss: 0.0037343\n",
      "Epoch 340, Training Loss: 0.0007228, Validation Loss: 0.0035887\n",
      "Epoch 341, Training Loss: 0.0006948, Validation Loss: 0.0034572\n",
      "Epoch 342, Training Loss: 0.0007172, Validation Loss: 0.0035828\n",
      "Epoch 343, Training Loss: 0.0007902, Validation Loss: 0.0038410\n",
      "Epoch 344, Training Loss: 0.0006805, Validation Loss: 0.0034442\n",
      "Epoch 345, Training Loss: 0.0006457, Validation Loss: 0.0033085\n",
      "Epoch 346, Training Loss: 0.0006793, Validation Loss: 0.0033977\n",
      "Epoch 347, Training Loss: 0.0007165, Validation Loss: 0.0035215\n",
      "Epoch 348, Training Loss: 0.0006959, Validation Loss: 0.0035366\n",
      "Epoch 349, Training Loss: 0.0007204, Validation Loss: 0.0034791\n",
      "Epoch 350, Training Loss: 0.0006974, Validation Loss: 0.0034858\n",
      "Epoch 351, Training Loss: 0.0006983, Validation Loss: 0.0034839\n",
      "Epoch 352, Training Loss: 0.0006867, Validation Loss: 0.0033981\n",
      "Epoch 353, Training Loss: 0.0006757, Validation Loss: 0.0034249\n",
      "Epoch 354, Training Loss: 0.0006962, Validation Loss: 0.0034934\n",
      "Epoch 355, Training Loss: 0.0006929, Validation Loss: 0.0035196\n",
      "Epoch 356, Training Loss: 0.0007289, Validation Loss: 0.0035695\n",
      "Epoch 357, Training Loss: 0.0006834, Validation Loss: 0.0033249\n",
      "Epoch 358, Training Loss: 0.0006639, Validation Loss: 0.0033922\n",
      "Epoch 359, Training Loss: 0.0006766, Validation Loss: 0.0033098\n",
      "Epoch 360, Training Loss: 0.0006626, Validation Loss: 0.0033576\n",
      "Epoch 361, Training Loss: 0.0006935, Validation Loss: 0.0034244\n",
      "Epoch 362, Training Loss: 0.0006504, Validation Loss: 0.0033457\n",
      "Epoch 363, Training Loss: 0.0006693, Validation Loss: 0.0034171\n",
      "Epoch 364, Training Loss: 0.0006352, Validation Loss: 0.0032623\n",
      "Epoch 365, Training Loss: 0.0006844, Validation Loss: 0.0033534\n",
      "Epoch 366, Training Loss: 0.0006993, Validation Loss: 0.0034954\n",
      "Epoch 367, Training Loss: 0.0006671, Validation Loss: 0.0033464\n",
      "Epoch 368, Training Loss: 0.0006681, Validation Loss: 0.0033145\n",
      "Epoch 369, Training Loss: 0.0006649, Validation Loss: 0.0033563\n",
      "Epoch 370, Training Loss: 0.0006635, Validation Loss: 0.0033696\n",
      "Epoch 371, Training Loss: 0.0006433, Validation Loss: 0.0032200\n",
      "Epoch 372, Training Loss: 0.0006525, Validation Loss: 0.0032117\n",
      "Epoch 373, Training Loss: 0.0006794, Validation Loss: 0.0033810\n",
      "Epoch 374, Training Loss: 0.0006606, Validation Loss: 0.0032919\n",
      "Epoch 375, Training Loss: 0.0006410, Validation Loss: 0.0032287\n",
      "Epoch 376, Training Loss: 0.0006505, Validation Loss: 0.0032598\n",
      "Epoch 377, Training Loss: 0.0006876, Validation Loss: 0.0034570\n",
      "Epoch 378, Training Loss: 0.0006799, Validation Loss: 0.0033660\n",
      "Epoch 379, Training Loss: 0.0006499, Validation Loss: 0.0032221\n",
      "Epoch 380, Training Loss: 0.0006648, Validation Loss: 0.0032852\n",
      "Epoch 381, Training Loss: 0.0006605, Validation Loss: 0.0032845\n",
      "Epoch 382, Training Loss: 0.0006556, Validation Loss: 0.0032669\n",
      "Epoch 383, Training Loss: 0.0006648, Validation Loss: 0.0033703\n",
      "Epoch 384, Training Loss: 0.0006761, Validation Loss: 0.0033726\n",
      "Epoch 385, Training Loss: 0.0006669, Validation Loss: 0.0033350\n",
      "Epoch 386, Training Loss: 0.0006410, Validation Loss: 0.0031847\n",
      "Epoch 387, Training Loss: 0.0006516, Validation Loss: 0.0032104\n",
      "Epoch 388, Training Loss: 0.0006519, Validation Loss: 0.0032419\n",
      "Epoch 389, Training Loss: 0.0006671, Validation Loss: 0.0033319\n",
      "Epoch 390, Training Loss: 0.0006555, Validation Loss: 0.0032397\n",
      "Epoch 391, Training Loss: 0.0006152, Validation Loss: 0.0031035\n",
      "Epoch 392, Training Loss: 0.0006309, Validation Loss: 0.0031636\n",
      "Epoch 393, Training Loss: 0.0006334, Validation Loss: 0.0031584\n",
      "Epoch 394, Training Loss: 0.0006349, Validation Loss: 0.0031621\n",
      "Epoch 395, Training Loss: 0.0006342, Validation Loss: 0.0032001\n",
      "Epoch 396, Training Loss: 0.0006362, Validation Loss: 0.0031915\n",
      "Epoch 397, Training Loss: 0.0006668, Validation Loss: 0.0032869\n",
      "Epoch 398, Training Loss: 0.0006129, Validation Loss: 0.0031612\n",
      "Epoch 399, Training Loss: 0.0006495, Validation Loss: 0.0032140\n",
      "Epoch 400, Training Loss: 0.0006926, Validation Loss: 0.0034239\n",
      "Epoch 401, Training Loss: 0.0006628, Validation Loss: 0.0033037\n",
      "Epoch 402, Training Loss: 0.0009844, Validation Loss: 0.0053631\n",
      "Epoch 403, Training Loss: 0.0009592, Validation Loss: 0.0046851\n",
      "Epoch 404, Training Loss: 0.0007652, Validation Loss: 0.0037858\n",
      "Epoch 405, Training Loss: 0.0007318, Validation Loss: 0.0036748\n",
      "Epoch 406, Training Loss: 0.0007210, Validation Loss: 0.0036445\n",
      "Epoch 407, Training Loss: 0.0006983, Validation Loss: 0.0034930\n",
      "Epoch 408, Training Loss: 0.0006484, Validation Loss: 0.0032946\n",
      "Epoch 409, Training Loss: 0.0006810, Validation Loss: 0.0032930\n",
      "Epoch 410, Training Loss: 0.0006725, Validation Loss: 0.0033487\n",
      "Epoch 411, Training Loss: 0.0006697, Validation Loss: 0.0033341\n",
      "Epoch 412, Training Loss: 0.0006593, Validation Loss: 0.0032765\n",
      "Epoch 413, Training Loss: 0.0006260, Validation Loss: 0.0031421\n",
      "Epoch 414, Training Loss: 0.0006295, Validation Loss: 0.0031713\n",
      "Epoch 415, Training Loss: 0.0006355, Validation Loss: 0.0031997\n",
      "Epoch 416, Training Loss: 0.0006586, Validation Loss: 0.0032635\n",
      "Epoch 417, Training Loss: 0.0006552, Validation Loss: 0.0032665\n",
      "Epoch 418, Training Loss: 0.0006615, Validation Loss: 0.0033110\n",
      "Epoch 419, Training Loss: 0.0006393, Validation Loss: 0.0032308\n",
      "Epoch 420, Training Loss: 0.0006096, Validation Loss: 0.0030592\n",
      "Epoch 421, Training Loss: 0.0006390, Validation Loss: 0.0032378\n",
      "Epoch 422, Training Loss: 0.0006231, Validation Loss: 0.0031542\n",
      "Epoch 423, Training Loss: 0.0006354, Validation Loss: 0.0031786\n",
      "Epoch 424, Training Loss: 0.0006518, Validation Loss: 0.0032263\n",
      "Epoch 425, Training Loss: 0.0006265, Validation Loss: 0.0031745\n",
      "Epoch 426, Training Loss: 0.0006472, Validation Loss: 0.0032079\n",
      "Epoch 427, Training Loss: 0.0006204, Validation Loss: 0.0031048\n",
      "Epoch 428, Training Loss: 0.0006545, Validation Loss: 0.0033016\n",
      "Epoch 429, Training Loss: 0.0006537, Validation Loss: 0.0032176\n",
      "Epoch 430, Training Loss: 0.0006467, Validation Loss: 0.0031829\n",
      "Epoch 431, Training Loss: 0.0006271, Validation Loss: 0.0031641\n",
      "Epoch 432, Training Loss: 0.0006385, Validation Loss: 0.0031436\n",
      "Epoch 433, Training Loss: 0.0006556, Validation Loss: 0.0033023\n",
      "Epoch 434, Training Loss: 0.0006345, Validation Loss: 0.0031724\n",
      "Epoch 435, Training Loss: 0.0006452, Validation Loss: 0.0032081\n",
      "Epoch 436, Training Loss: 0.0006494, Validation Loss: 0.0031824\n",
      "Epoch 437, Training Loss: 0.0006367, Validation Loss: 0.0031543\n",
      "Epoch 438, Training Loss: 0.0006400, Validation Loss: 0.0032251\n",
      "Epoch 439, Training Loss: 0.0006269, Validation Loss: 0.0031193\n",
      "Epoch 440, Training Loss: 0.0006212, Validation Loss: 0.0031115\n",
      "Epoch 441, Training Loss: 0.0006402, Validation Loss: 0.0032094\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m loss_function \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Training and Validation\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m training_losses, validate_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 111\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, device, train_loader, val_loader, optimizer, loss_function, epochs)\u001b[0m\n\u001b[0;32m    109\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_function(output, target)\n\u001b[0;32m    110\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m--> 111\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    112\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m data\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    113\u001b[0m training_avg_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset)\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\envs\\fyp\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    369\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    370\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    371\u001b[0m             )\n\u001b[1;32m--> 373\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    376\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\envs\\fyp\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\envs\\fyp\\lib\\site-packages\\torch\\optim\\adam.py:163\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    152\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    155\u001b[0m         group,\n\u001b[0;32m    156\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    160\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m         state_steps)\n\u001b[1;32m--> 163\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\envs\\fyp\\lib\\site-packages\\torch\\optim\\adam.py:311\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    309\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 311\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    312\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    315\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\glori\\anaconda3\\envs\\fyp\\lib\\site-packages\\torch\\optim\\adam.py:434\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    432\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 434\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the model and other components\n",
    "model = LocalizationCNN().to(device)\n",
    "# model = VelocityCNN().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# Training and Validation\n",
    "training_losses, validate_losses = train_model(model, device, train_loader, val_loader, optimizer, loss_function, epochs=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0150, -0.0050,  0.0000,  0.0300, -0.0110,  0.0000],\n",
       "        [ 0.0130, -0.0090,  0.0000,  0.0260, -0.0180,  0.0000],\n",
       "        [ 0.0110, -0.0120,  0.0000,  0.0210, -0.0240,  0.0000],\n",
       "        [ 0.0070, -0.0140,  0.0000,  0.0140, -0.0280,  0.0000],\n",
       "        [ 0.0030, -0.0160,  0.0000,  0.0070, -0.0310,  0.0000],\n",
       "        [-0.0000, -0.0160,  0.0000, -0.0010, -0.0320,  0.0000],\n",
       "        [-0.0040, -0.0150,  0.0000, -0.0090, -0.0310,  0.0000],\n",
       "        [-0.0080, -0.0140,  0.0000, -0.0160, -0.0280,  0.0000],\n",
       "        [-0.0110, -0.0110,  0.0000, -0.0220, -0.0230,  0.0000],\n",
       "        [-0.0140, -0.0080,  0.0000, -0.0270, -0.0160,  0.0000],\n",
       "        [-0.0150, -0.0050,  0.0000, -0.0310, -0.0090,  0.0000],\n",
       "        [-0.0160, -0.0010,  0.0000, -0.0320, -0.0010,  0.0000],\n",
       "        [-0.0160,  0.0030,  0.0000, -0.0310,  0.0070,  0.0000],\n",
       "        [-0.0140,  0.0070,  0.0000, -0.0290,  0.0140,  0.0000],\n",
       "        [-0.0120,  0.0100,  0.0000, -0.0240,  0.0210,  0.0000],\n",
       "        [-0.0090,  0.0130,  0.0000, -0.0180,  0.0260,  0.0000],\n",
       "        [-0.0060,  0.0150,  0.0000, -0.0110,  0.0300,  0.0000],\n",
       "        [-0.0020,  0.0160,  0.0000, -0.0040,  0.0320,  0.0000],\n",
       "        [ 0.0020,  0.0160,  0.0000,  0.0040,  0.0320,  0.0000],\n",
       "        [ 0.0060,  0.0150,  0.0000,  0.0120,  0.0300,  0.0000],\n",
       "        [ 0.0100,  0.0130,  0.0000,  0.0190,  0.0260,  0.0000],\n",
       "        [ 0.0120,  0.0100,  0.0000,  0.0250,  0.0200,  0.0000],\n",
       "        [ 0.0140,  0.0070,  0.0000,  0.0290,  0.0130,  0.0000],\n",
       "        [ 0.0160,  0.0030,  0.0000,  0.0310,  0.0060,  0.0000],\n",
       "        [ 0.0160, -0.0010,  0.0000,  0.0320, -0.0020,  0.0000],\n",
       "        [ 0.0150, -0.0050,  0.0000,  0.0300, -0.0100,  0.0000],\n",
       "        [ 0.0130, -0.0090,  0.0000,  0.0270, -0.0170,  0.0000],\n",
       "        [ 0.0110, -0.0120,  0.0000,  0.0220, -0.0230,  0.0000],\n",
       "        [ 0.0080, -0.0140,  0.0000,  0.0150, -0.0280,  0.0000],\n",
       "        [ 0.0040, -0.0150,  0.0000,  0.0080, -0.0310,  0.0000],\n",
       "        [ 0.0000, -0.0160,  0.0000,  0.0000, -0.0320,  0.0000],\n",
       "        [-0.0040, -0.0150,  0.0000, -0.0080, -0.0310,  0.0000],\n",
       "        [-0.0080, -0.0140,  0.0000, -0.0150, -0.0280,  0.0000],\n",
       "        [-0.0110, -0.0120,  0.0000, -0.0220, -0.0230,  0.0000],\n",
       "        [-0.0130, -0.0090,  0.0000, -0.0270, -0.0170,  0.0000],\n",
       "        [-0.0150, -0.0050,  0.0000, -0.0300, -0.0100,  0.0000],\n",
       "        [-0.0160, -0.0010,  0.0000, -0.0320, -0.0020,  0.0000],\n",
       "        [-0.0160,  0.0030,  0.0000, -0.0310,  0.0060,  0.0000],\n",
       "        [-0.0150,  0.0070,  0.0000, -0.0290,  0.0130,  0.0000],\n",
       "        [-0.0120,  0.0100,  0.0000, -0.0250,  0.0200,  0.0000],\n",
       "        [ 0.0150, -0.0050,  0.0000,  0.0300, -0.0110,  0.0000],\n",
       "        [ 0.0130, -0.0090,  0.0000,  0.0260, -0.0180,  0.0000],\n",
       "        [ 0.0110, -0.0120,  0.0000,  0.0210, -0.0240,  0.0000],\n",
       "        [ 0.0070, -0.0140,  0.0000,  0.0140, -0.0280,  0.0000],\n",
       "        [ 0.0030, -0.0160,  0.0000,  0.0070, -0.0310,  0.0000],\n",
       "        [-0.0000, -0.0160,  0.0000, -0.0010, -0.0320,  0.0000],\n",
       "        [-0.0040, -0.0150,  0.0000, -0.0090, -0.0310,  0.0000],\n",
       "        [-0.0080, -0.0140,  0.0000, -0.0160, -0.0280,  0.0000],\n",
       "        [-0.0110, -0.0110,  0.0000, -0.0220, -0.0230,  0.0000],\n",
       "        [-0.0140, -0.0080,  0.0000, -0.0270, -0.0160,  0.0000],\n",
       "        [-0.0150, -0.0050,  0.0000, -0.0310, -0.0090,  0.0000],\n",
       "        [-0.0160, -0.0010,  0.0000, -0.0320, -0.0010,  0.0000],\n",
       "        [-0.0160,  0.0030,  0.0000, -0.0310,  0.0070,  0.0000],\n",
       "        [-0.0140,  0.0070,  0.0000, -0.0290,  0.0140,  0.0000],\n",
       "        [-0.0120,  0.0100,  0.0000, -0.0240,  0.0210,  0.0000],\n",
       "        [-0.0090,  0.0130,  0.0000, -0.0180,  0.0260,  0.0000],\n",
       "        [-0.0060,  0.0150,  0.0000, -0.0110,  0.0300,  0.0000],\n",
       "        [-0.0020,  0.0160,  0.0000, -0.0040,  0.0320,  0.0000],\n",
       "        [ 0.0020,  0.0160,  0.0000,  0.0040,  0.0320,  0.0000],\n",
       "        [ 0.0060,  0.0150,  0.0000,  0.0120,  0.0300,  0.0000],\n",
       "        [ 0.0100,  0.0130,  0.0000,  0.0190,  0.0260,  0.0000],\n",
       "        [ 0.0120,  0.0100,  0.0000,  0.0250,  0.0200,  0.0000],\n",
       "        [ 0.0140,  0.0070,  0.0000,  0.0290,  0.0130,  0.0000],\n",
       "        [ 0.0160,  0.0030,  0.0000,  0.0310,  0.0060,  0.0000],\n",
       "        [ 0.0160, -0.0010,  0.0000,  0.0320, -0.0020,  0.0000],\n",
       "        [ 0.0150, -0.0050,  0.0000,  0.0300, -0.0100,  0.0000],\n",
       "        [ 0.0130, -0.0090,  0.0000,  0.0270, -0.0170,  0.0000],\n",
       "        [ 0.0110, -0.0120,  0.0000,  0.0220, -0.0230,  0.0000],\n",
       "        [ 0.0080, -0.0140,  0.0000,  0.0150, -0.0280,  0.0000],\n",
       "        [ 0.0040, -0.0150,  0.0000,  0.0080, -0.0310,  0.0000],\n",
       "        [ 0.0000, -0.0160,  0.0000,  0.0000, -0.0320,  0.0000],\n",
       "        [-0.0040, -0.0150,  0.0000, -0.0080, -0.0310,  0.0000],\n",
       "        [-0.0080, -0.0140,  0.0000, -0.0150, -0.0280,  0.0000],\n",
       "        [-0.0110, -0.0120,  0.0000, -0.0220, -0.0230,  0.0000],\n",
       "        [-0.0130, -0.0090,  0.0000, -0.0270, -0.0170,  0.0000],\n",
       "        [-0.0150, -0.0050,  0.0000, -0.0300, -0.0100,  0.0000],\n",
       "        [-0.0160, -0.0010,  0.0000, -0.0320, -0.0020,  0.0000],\n",
       "        [-0.0160,  0.0030,  0.0000, -0.0310,  0.0060,  0.0000],\n",
       "        [-0.0150,  0.0070,  0.0000, -0.0290,  0.0130,  0.0000],\n",
       "        [-0.0120,  0.0100,  0.0000, -0.0250,  0.0200,  0.0000],\n",
       "        [ 0.0150, -0.0050,  0.0000,  0.0300, -0.0110,  0.0000],\n",
       "        [ 0.0130, -0.0090,  0.0000,  0.0260, -0.0180,  0.0000],\n",
       "        [ 0.0110, -0.0120,  0.0000,  0.0210, -0.0240,  0.0000],\n",
       "        [ 0.0070, -0.0140,  0.0000,  0.0140, -0.0280,  0.0000],\n",
       "        [ 0.0030, -0.0160,  0.0000,  0.0070, -0.0310,  0.0000],\n",
       "        [-0.0000, -0.0160,  0.0000, -0.0010, -0.0320,  0.0000],\n",
       "        [-0.0040, -0.0150,  0.0000, -0.0090, -0.0310,  0.0000],\n",
       "        [-0.0080, -0.0140,  0.0000, -0.0160, -0.0280,  0.0000],\n",
       "        [-0.0110, -0.0110,  0.0000, -0.0220, -0.0230,  0.0000],\n",
       "        [-0.0140, -0.0080,  0.0000, -0.0270, -0.0160,  0.0000],\n",
       "        [-0.0150, -0.0050,  0.0000, -0.0310, -0.0090,  0.0000],\n",
       "        [-0.0160, -0.0010,  0.0000, -0.0320, -0.0010,  0.0000],\n",
       "        [-0.0160,  0.0030,  0.0000, -0.0310,  0.0070,  0.0000],\n",
       "        [-0.0140,  0.0070,  0.0000, -0.0290,  0.0140,  0.0000],\n",
       "        [-0.0120,  0.0100,  0.0000, -0.0240,  0.0210,  0.0000],\n",
       "        [-0.0090,  0.0130,  0.0000, -0.0180,  0.0260,  0.0000],\n",
       "        [-0.0060,  0.0150,  0.0000, -0.0110,  0.0300,  0.0000],\n",
       "        [-0.0020,  0.0160,  0.0000, -0.0040,  0.0320,  0.0000],\n",
       "        [ 0.0020,  0.0160,  0.0000,  0.0040,  0.0320,  0.0000],\n",
       "        [ 0.0060,  0.0150,  0.0000,  0.0120,  0.0300,  0.0000]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(Y[:100], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0080, -0.0060,  0.0000,  0.0190, -0.0120, -0.0000],\n",
       "        [ 0.0100, -0.0090, -0.0000,  0.0200, -0.0180, -0.0000],\n",
       "        [ 0.0110, -0.0100, -0.0000,  0.0230, -0.0200, -0.0000],\n",
       "        [ 0.0030, -0.0140, -0.0000,  0.0070, -0.0280, -0.0000],\n",
       "        [ 0.0050, -0.0170, -0.0000,  0.0100, -0.0350, -0.0000],\n",
       "        [-0.0000, -0.0170, -0.0000, -0.0010, -0.0340,  0.0000],\n",
       "        [-0.0060, -0.0160, -0.0000, -0.0120, -0.0310,  0.0000],\n",
       "        [-0.0040, -0.0110, -0.0000, -0.0070, -0.0220,  0.0000],\n",
       "        [-0.0090, -0.0140,  0.0000, -0.0190, -0.0280,  0.0000],\n",
       "        [-0.0170, -0.0070,  0.0000, -0.0340, -0.0140, -0.0000],\n",
       "        [-0.0190, -0.0030,  0.0000, -0.0390, -0.0070, -0.0000],\n",
       "        [-0.0190,  0.0010,  0.0000, -0.0400,  0.0020, -0.0000],\n",
       "        [-0.0130,  0.0040,  0.0000, -0.0250,  0.0080, -0.0000],\n",
       "        [-0.0170,  0.0120, -0.0000, -0.0340,  0.0240, -0.0000],\n",
       "        [-0.0100,  0.0140,  0.0000, -0.0190,  0.0270, -0.0000],\n",
       "        [-0.0050,  0.0090,  0.0000, -0.0100,  0.0170, -0.0000],\n",
       "        [-0.0060,  0.0200,  0.0000, -0.0120,  0.0400, -0.0000],\n",
       "        [-0.0030,  0.0180,  0.0000, -0.0070,  0.0350, -0.0000],\n",
       "        [ 0.0040,  0.0220,  0.0000,  0.0080,  0.0450, -0.0000],\n",
       "        [ 0.0110,  0.0160,  0.0000,  0.0220,  0.0340, -0.0000],\n",
       "        [-0.0000,  0.0020, -0.0000,  0.0000,  0.0040, -0.0000],\n",
       "        [ 0.0110,  0.0140,  0.0000,  0.0220,  0.0290, -0.0000],\n",
       "        [ 0.0210,  0.0000,  0.0000,  0.0420,  0.0010, -0.0000],\n",
       "        [ 0.0080,  0.0020,  0.0000,  0.0150,  0.0050,  0.0000],\n",
       "        [ 0.0230,  0.0020,  0.0000,  0.0460,  0.0030, -0.0000],\n",
       "        [ 0.0180, -0.0050,  0.0000,  0.0370, -0.0100, -0.0000],\n",
       "        [ 0.0090, -0.0080,  0.0000,  0.0180, -0.0150,  0.0000],\n",
       "        [ 0.0100, -0.0050,  0.0000,  0.0210, -0.0110, -0.0000],\n",
       "        [ 0.0110, -0.0150, -0.0000,  0.0230, -0.0310, -0.0000],\n",
       "        [ 0.0040, -0.0100, -0.0000,  0.0090, -0.0210, -0.0000],\n",
       "        [-0.0000, -0.0080,  0.0000,  0.0000, -0.0170, -0.0000],\n",
       "        [-0.0060, -0.0150, -0.0000, -0.0120, -0.0310,  0.0000],\n",
       "        [-0.0080, -0.0160,  0.0000, -0.0170, -0.0310,  0.0000],\n",
       "        [-0.0100, -0.0130,  0.0000, -0.0210, -0.0250,  0.0000],\n",
       "        [-0.0150, -0.0080,  0.0000, -0.0310, -0.0160,  0.0000],\n",
       "        [-0.0040, -0.0060, -0.0000, -0.0080, -0.0130, -0.0000],\n",
       "        [-0.0150, -0.0000, -0.0000, -0.0300, -0.0000, -0.0000],\n",
       "        [-0.0120,  0.0040,  0.0000, -0.0230,  0.0080, -0.0000],\n",
       "        [-0.0090,  0.0030,  0.0000, -0.0180,  0.0070, -0.0000],\n",
       "        [-0.0080, -0.0000, -0.0000, -0.0160, -0.0010,  0.0000],\n",
       "        [ 0.0090, -0.0010,  0.0000,  0.0190, -0.0010, -0.0000],\n",
       "        [ 0.0130, -0.0090, -0.0000,  0.0260, -0.0180, -0.0000],\n",
       "        [ 0.0130, -0.0080, -0.0000,  0.0270, -0.0170, -0.0000],\n",
       "        [ 0.0070, -0.0110, -0.0000,  0.0150, -0.0220, -0.0000],\n",
       "        [-0.0000, -0.0150, -0.0000,  0.0000, -0.0310,  0.0000],\n",
       "        [ 0.0020, -0.0150, -0.0000,  0.0050, -0.0300,  0.0000],\n",
       "        [-0.0020, -0.0070, -0.0000, -0.0040, -0.0150, -0.0000],\n",
       "        [-0.0090, -0.0140,  0.0000, -0.0190, -0.0280,  0.0000],\n",
       "        [-0.0100, -0.0130,  0.0000, -0.0210, -0.0260,  0.0000],\n",
       "        [-0.0110, -0.0050, -0.0000, -0.0210, -0.0100, -0.0000],\n",
       "        [-0.0180, -0.0050,  0.0000, -0.0370, -0.0110, -0.0000],\n",
       "        [-0.0130, -0.0070,  0.0000, -0.0270, -0.0130,  0.0000],\n",
       "        [-0.0180,  0.0020, -0.0000, -0.0370,  0.0030, -0.0000],\n",
       "        [-0.0170,  0.0090,  0.0000, -0.0340,  0.0170, -0.0000],\n",
       "        [-0.0120,  0.0100,  0.0000, -0.0250,  0.0200, -0.0000],\n",
       "        [-0.0100,  0.0190,  0.0000, -0.0200,  0.0380, -0.0000],\n",
       "        [-0.0050,  0.0170,  0.0000, -0.0100,  0.0330,  0.0000],\n",
       "        [-0.0050,  0.0180,  0.0000, -0.0100,  0.0370, -0.0000],\n",
       "        [ 0.0050,  0.0070, -0.0000,  0.0100,  0.0150,  0.0000],\n",
       "        [ 0.0100,  0.0010,  0.0000,  0.0210,  0.0030, -0.0000],\n",
       "        [ 0.0130,  0.0200,  0.0000,  0.0260,  0.0420, -0.0000],\n",
       "        [ 0.0060,  0.0120,  0.0000,  0.0120,  0.0230, -0.0000],\n",
       "        [ 0.0170,  0.0140,  0.0000,  0.0340,  0.0290, -0.0000],\n",
       "        [ 0.0230,  0.0060,  0.0000,  0.0470,  0.0120, -0.0000],\n",
       "        [ 0.0110, -0.0030, -0.0000,  0.0220, -0.0070, -0.0000],\n",
       "        [ 0.0070, -0.0060, -0.0000,  0.0130, -0.0120, -0.0000],\n",
       "        [ 0.0090, -0.0090, -0.0000,  0.0190, -0.0180, -0.0000],\n",
       "        [ 0.0090, -0.0110, -0.0000,  0.0180, -0.0210, -0.0000],\n",
       "        [ 0.0100, -0.0100, -0.0000,  0.0200, -0.0210, -0.0000],\n",
       "        [ 0.0030, -0.0110, -0.0000,  0.0060, -0.0220, -0.0000],\n",
       "        [-0.0030, -0.0090,  0.0000, -0.0070, -0.0190, -0.0000],\n",
       "        [-0.0060, -0.0160, -0.0000, -0.0120, -0.0310,  0.0000],\n",
       "        [-0.0040, -0.0060, -0.0000, -0.0080, -0.0130, -0.0000],\n",
       "        [-0.0090, -0.0100,  0.0000, -0.0190, -0.0200,  0.0000],\n",
       "        [-0.0110, -0.0050, -0.0000, -0.0210, -0.0100, -0.0000],\n",
       "        [-0.0140, -0.0010, -0.0000, -0.0270, -0.0010, -0.0000],\n",
       "        [-0.0200,  0.0010,  0.0000, -0.0410,  0.0020, -0.0000],\n",
       "        [-0.0200,  0.0020, -0.0000, -0.0410,  0.0040, -0.0000],\n",
       "        [-0.0090,  0.0030,  0.0000, -0.0190,  0.0070, -0.0000],\n",
       "        [-0.0100,  0.0120,  0.0000, -0.0200,  0.0240, -0.0000],\n",
       "        [ 0.0110, -0.0060, -0.0000,  0.0230, -0.0110, -0.0000],\n",
       "        [ 0.0070, -0.0050,  0.0000,  0.0150, -0.0110, -0.0000],\n",
       "        [ 0.0130, -0.0130, -0.0000,  0.0270, -0.0260, -0.0000],\n",
       "        [ 0.0080, -0.0170, -0.0000,  0.0160, -0.0340, -0.0000],\n",
       "        [-0.0040, -0.0140, -0.0000, -0.0080, -0.0270,  0.0000],\n",
       "        [-0.0030, -0.0160, -0.0000, -0.0070, -0.0330,  0.0000],\n",
       "        [-0.0070, -0.0150,  0.0000, -0.0150, -0.0300,  0.0000],\n",
       "        [-0.0050, -0.0110, -0.0000, -0.0090, -0.0220,  0.0000],\n",
       "        [-0.0110, -0.0130,  0.0000, -0.0230, -0.0260,  0.0000],\n",
       "        [-0.0160, -0.0080,  0.0000, -0.0330, -0.0160,  0.0000],\n",
       "        [-0.0190, -0.0040,  0.0000, -0.0380, -0.0070, -0.0000],\n",
       "        [-0.0190,  0.0010,  0.0000, -0.0390,  0.0010, -0.0000],\n",
       "        [-0.0180,  0.0060,  0.0000, -0.0370,  0.0130, -0.0000],\n",
       "        [-0.0120,  0.0090, -0.0000, -0.0230,  0.0190,  0.0000],\n",
       "        [-0.0150,  0.0160,  0.0000, -0.0290,  0.0320, -0.0000],\n",
       "        [-0.0100,  0.0110,  0.0000, -0.0190,  0.0230, -0.0000],\n",
       "        [-0.0060,  0.0170,  0.0000, -0.0110,  0.0350,  0.0000],\n",
       "        [-0.0020,  0.0190,  0.0000, -0.0040,  0.0380, -0.0000],\n",
       "        [-0.0040,  0.0100,  0.0000, -0.0070,  0.0200, -0.0000],\n",
       "        [-0.0010,  0.0090, -0.0000, -0.0010,  0.0170,  0.0000]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model(X[:100]), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'localization_cnn32.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'velocity_cnn32.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curves\n",
    "plot_learning_curves(training_losses, validate_losses, 10, 'Training and Validation Losses for 32x32 Velocity CNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training and validation losses\n",
    "np.save('loc_training_losses32.npy', training_losses)\n",
    "np.save('loc_validate_losses32.npy', validate_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the training and validation losses\n",
    "np.save('vel_training_losses32.npy', training_losses)\n",
    "np.save('vel_validate_losses32.npy', validate_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the learning curves\n",
    "plot_learning_curves(training_losses, validate_losses, 0, 'Training and Validation Losses for 32x32 Localisation CNN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
